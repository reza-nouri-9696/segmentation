# -*- coding: utf-8 -*-
"""dataset_unet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R7e61t4qXJhzxXbjM0XTBoILLwGDq2LE
"""

import argparse
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm
import matplotlib.pyplot as plt
from dataset import CustomDataset
from model import VAEnet

def train(train_loader, valid_loader, model, optimizer, loss_func, device, epochs, output_path):
    train_loss = []
    val_loss = []

    for epoch in range(epochs):
        trainloss = 0
        valloss = 0

        model.train()
        for img, lab in tqdm(train_loader):
            optimizer.zero_grad()
            img = img.to(device)
            lab = lab.to(device)
            output = model(img)
            loss = loss_func(output, lab)
            loss.backward()
            optimizer.step()
            trainloss += loss.item()

        train_loss.append(trainloss / len(train_loader))

        model.eval()
        with torch.no_grad():
            for img, lab in tqdm(valid_loader):
                img = img.to(device)
                lab = lab.to(device)
                output = model(img)
                loss = loss_func(output, lab)
                valloss += loss.item()

        val_loss.append(valloss / len(valid_loader))

        print("epoch : {} ,train loss : {} ,valid loss : {} ".format(epoch, train_loss[-1], val_loss[-1]))

        # Save model after each epoch
        torch.save(model.state_dict(), f'{output_path}/model_epoch_{epoch}.pth')

    plt.plot(train_loss, color='b', label='train loss')
    plt.plot(val_loss, color='r', label='val_loss')
    plt.legend()
    plt.savefig(f'{output_path}/training_plot.png')

def main(train_path, val_path, output_path, epochs):
    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    # Define transformations
    myTransformImage = transforms.Compose([
        transforms.ToTensor(),
    ])
    myTransformLabel = transforms.Compose([
        transforms.ToTensor(),
    ])

    # Create datasets
    train_dataset = CustomDataset(train_path, myTransformImage, myTransformLabel)
    valid_dataset = CustomDataset(val_path, myTransformImage, myTransformLabel)

    # Create data loaders
    batch_size = 5
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    valid_loader = DataLoader(valid_dataset, 1, shuffle=True)

    # Create model
    model = VAEnet().float().to(device)

    # Define loss function and optimizer
    loss_func = nn.MSELoss()
    lr = 0.01
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)

    # Train the model
    train(train_loader, valid_loader, model, optimizer, loss_func, device, epochs, output_path)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Train VAE-net model')
    parser.add_argument('--train_path', type=str, help='Path to training data')
    parser.add_argument('--val_path', type=str, help='Path to validation data')
    parser.add_argument('--output_path', type=str, help='Path to save output plot and model')
    parser.add_argument('--epochs', type=int, default=30, help='Number of epochs for training')
    args = parser.parse_args()

    main(args.train_path, args.val_path, args.output_path, args.epochs)